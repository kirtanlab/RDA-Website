<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>INDRA | Road Crossing Assistant</title>
    <style>
        /* Base Styles */
        :root {
            --primary-font: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;
            --text-color: rgba(0, 0, 0, 0.84);
            --light-text: rgba(0, 0, 0, 0.54);
            --lightest-text: rgba(0, 0, 0, 0.34);
            --accent-color: #03a87c;
            --light-accent: rgba(3, 168, 124, 0.1);
            --border-color: rgba(0, 0, 0, 0.1);
            --background: #fff;
            --light-background: #fafafa;
            --highlight: #f8f9fa;
            --safe: #02b875;
            --unsafe: #e25555;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: var(--primary-font);
            color: var(--text-color);
            line-height: 1.6;
            background-color: var(--background);
            font-size: 18px;
            -webkit-font-smoothing: antialiased;
        }
        
        /* Typography */
        h1, h2, h3, h4, h5 {
            font-weight: 700;
            margin-bottom: 0.5em;
            line-height: 1.3;
            color: var(--text-color);
            letter-spacing: -0.02em;
        }
        
        h1 {
            font-size: 42px;
            margin-bottom: 0.3em;
            letter-spacing: -0.03em;
        }
        
        h2 {
            font-size: 34px;
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        
        h3 {
            font-size: 26px;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }
        
        h4 {
            font-size: 22px;
        }
        
        p {
            margin-bottom: 1.5em;
            font-size: 18px;
            line-height: 1.7;
            color: var(--text-color);
        }
        
        a {
            color: var(--accent-color);
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        /* Layout */
        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0 10px;
        }
        
        .narrow-container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        header {
            padding: 10px 0;
            border-bottom: 1px solid var(--border-color);
            background-color: var(--background);
            position: sticky;
            top: 0;
            z-index: 1000;
        }
        
        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .logo {
            font-weight: 700;
            font-size: 24px;
            color: var(--text-color);
            text-decoration: none;
        }
        
        .nav-links {
            display: flex;
            list-style: none;
        }
        
        .nav-links li {
            margin-left: 24px;
        }
        
        .nav-links a {
            color: var(--light-text);
            text-decoration: none;
            font-size: 16px;
            transition: color 0.2s;
        }
        
        .nav-links a:hover {
            color: var(--text-color);
            text-decoration: none;
        }
        
        .hero {
            display: flex;
            flex-direction: column;
            justify-content: center;
            padding: 80px 0 50px;
            background-color: var(--background);
        }
        
        .tagline {
            font-size: 20px;
            color: var(--light-text);
            margin-bottom: 1.5em;
            line-height: 1.6;
        }
        
        section {
            padding: 40px 0;
        }
        
        section.alt {
            background-color: var(--light-background);
        }
        
        footer {
            padding: 50px 0;
            background-color: var(--light-background);
            color: var(--light-text);
            font-size: 16px;
            text-align: center;
            border-top: 1px solid var(--border-color);
        }
        
        .divider {
            display: block;
            width: 100%;
            max-width: 50px;
            height: 2px;
            background-color: var(--border-color);
            margin: 30px 0;
        }
        
        /* Components */
        .btn {
            display: inline-block;
            background-color: var(--accent-color);
            color: white;
            padding: 8px 16px;
            border-radius: 4px;
            font-size: 16px;
            font-weight: 500;
            transition: background-color 0.3s;
        }
        
        .btn:hover {
            background-color: #028a65;
            text-decoration: none;
        }
        
        .btn-outline {
            display: inline-block;
            background-color: transparent;
            color: var(--accent-color);
            border: 1px solid var(--accent-color);
            padding: 8px 16px;
            border-radius: 4px;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s;
        }
        
        .btn-outline:hover {
            background-color: var(--light-accent);
            text-decoration: none;
        }
        
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }
        
        .feature-card {
            padding: 30px;
            background-color: var(--background);
            border-radius: 4px;
            border: 1px solid var(--border-color);
        }
        
        .feature-card h3 {
            font-size: 22px;
            margin-top: 0;
        }
        
        .feature-icon {
            font-size: 32px;
            margin-bottom: 20px;
            color: var(--accent-color);
        }
        
        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .image-frame {
            border-radius: 4px;
            overflow: hidden;
            aspect-ratio: 16/9;
        }
        
        .image-frame img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .safe-frame {
            border: 2px solid var(--safe);
        }
        
        .unsafe-frame {
            border: 2px solid var(--unsafe);
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            font-size: 16px;
        }
        
        th, td {
            padding: 12px 16px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }
        
        th {
            font-weight: 600;
            color: var(--light-text);
        }
        
        .highlight-row {
            background-color: var(--light-accent);
        }
        
        .card {
            margin: 30px 0;
            padding: 30px;
            background-color: var(--background);
            border-radius: 4px;
            border: 1px solid var(--border-color);
        }
        
        .model-card {
            background-color: var(--highlight);
            padding: 30px;
            margin: 30px 0;
            border-radius: 4px;
        }
        
        .model-image {
            width: 100%;
            max-width: 700px;
            margin: 20px auto;
            display: block;
            border-radius: 4px;
        }
        
        .hardware-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .hardware-item {
            padding: 20px;
            background-color: var(--highlight);
            border-radius: 4px;
            text-align: center;
        }
        
        .hardware-item img {
            width: 80px;
            height: 80px;
            object-fit: contain;
            margin-bottom: 15px;
        }
        
        .hardware-item h4 {
            font-size: 18px;
            margin-bottom: 8px;
        }
        
        .hardware-item p {
            font-size: 16px;
            color: var(--light-text);
            margin-bottom: 0;
        }
        
        blockquote {
            border-left: 3px solid var(--accent-color);
            padding-left: 20px;
            margin: 30px 0;
            font-style: italic;
            color: var(--light-text);
        }
        
        .team-member {
            text-align: center;
            margin: 30px 0;
        }
        
        .team-member img {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            object-fit: cover;
            margin-bottom: 15px;
        }
        
        .figure {
            margin: 30px 0;
            text-align: center;
        }
        
        .figure img {
            max-width: 100%;
            border-radius: 4px;
        }
        
        .figure-caption {
            margin-top: 10px;
            font-size: 16px;
            color: var(--light-text);
        }
        
        /* Lists */
        ul, ol {
            margin: 0 0 1.5em 1.5em;
        }
        
        ul li, ol li {
            margin-bottom: 0.5em;
        }
        
        /* Code */
        code {
            font-family: monospace;
            background-color: var(--highlight);
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 16px;
        }
        
        /* Utility Classes */
        .text-center {
            text-align: center;
        }
        
        .mt-lg {
            margin-top: 60px;
        }
        
        .mb-lg {
            margin-bottom: 60px;
        }
        
        .subtle {
            color: var(--light-text);
        }
        
        .very-subtle {
            color: var(--lightest-text);
        }
        
        .accent {
            color: var(--accent-color);
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            .nav-links {
                display: none;
            }
            
            h1 {
                font-size: 36px;
            }
            
            h2 {
                font-size: 28px;
            }
            
            h3 {
                font-size: 22px;
            }
            
            .container, .narrow-container {
                padding: 0 20px;
            }
            
            .hero {
                padding: 60px 0 40px;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <nav>
                <a href="#" class="logo">INDRA</a>
                <ul class="nav-links">
                    <li><a href="#home">Home</a></li>
                    <li><a href="#dataset">Dataset</a></li>
                    <li><a href="#model">Model</a></li>
                    <li><a href="#deployment">Deployment</a></li>
                    <li><a href="#about">About</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section id="home" class="hero">
        <div class="narrow-container">
            <h1>Road Crossing Assistant</h1>
            <p class="tagline">Helping visually impaired individuals safely navigate roads in Indian towns where traffic stops are often absent or disregarded.</p>
            
            <p>Roads in medium-sized Indian towns often have lots of traffic but no (or disregarded) traffic stops. This makes it hard for the blind to cross roads safely, because vision is crucial to determine when crossing is safe. Automatic and reliable image-based safety classifiers thus have the potential to help the blind to cross Indian roads.</p>
            
            <div class="feature-grid">
                <div class="feature-card">
                    <div class="feature-icon">ðŸ“Š</div>
                    <h3>INDRA Dataset</h3>
                    <p>INdian Dataset for RoAd crossing â€” the first dataset capturing videos of Indian roads from the pedestrian point-of-view.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">ðŸ§ª</div>
                    <h3>Specialized Annotations</h3>
                    <p>104 videos comprising of 26k 1080p frames, each annotated with binary road crossing safety labels and vehicle bounding boxes.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">ðŸ¤–</div>
                    <h3>MobileNetV3-LSTM Model</h3>
                    <p>A novel architecture tailored for deployment on the Nvidia Jetson Nano with 88% recall at 87% precision.</p>
                </div>
            </div>
            
            <div class="text-center mt-lg">
                <p class="subtle">Oral Presentation at ICVGIP 2022</p>
                <a href="#" class="btn">Watch Presentation</a>
            </div>
        </div>
    </section>

    <section id="dataset" class="alt">
        <div class="narrow-container">
            <h2>INDRA Dataset</h2>
            <p>We introduce INDRA (INdian Dataset for RoAd crossing), the first dataset capturing videos of Indian roads from the pedestrian point-of-view.</p>
            
            <div class="card">
                <h3>Dataset Specifications</h3>
                <p>Our INDRA dataset includes:</p>
                <ul>
                    <li>104 videos from diverse locations, times, and traffic patterns</li>
                    <li>Collected using an action camera from different roads of Anand, Gujarat</li>
                    <li>Video Format: MOV</li>
                    <li>Resolution: 1920Ã—1080</li>
                    <li>Framerate: 30 fps</li>
                    <li>More than 26,000 frames in total</li>
                </ul>
                
                <div class="divider"></div>
                
                <h3>Annotations</h3>
                <p>Each video is annotated with:</p>
                <ul>
                    <li>Time instances when the road is safe to cross</li>
                    <li>Time instances when the safe duration ends</li>
                    <li>Binary safety labels for each frame (safe/unsafe)</li>
                    <li>Vehicle bounding box annotations</li>
                </ul>
                
                <div class="divider"></div>
                
                <h3>Sample Frames</h3>
                <p>Below are sample frames showcasing both safe and unsafe road crossing scenarios:</p>
                
                <h4>Safe Crossing Frames</h4>
                <div class="image-grid">
                    <div class="image-frame safe-frame">
                        <img src="assets\img\GreenFrame1.png" alt="Safe Frame">
                    </div>
                    <div class="image-frame safe-frame">
                        <img src="assets\img\GreenFrame2.png" alt="Safe Frame">
                    </div>
                    <div class="image-frame safe-frame">
                        <img src="assets\img\GreenFrame3.png" alt="Safe Frame">
                    </div>
                    <div class="image-frame safe-frame">
                        <img src="assets\img\GreenFrame4.png" alt="Safe Frame">
                    </div>
                </div>
                
                <h4>Unsafe Crossing Frames</h4>
                <div class="image-grid">
                    <div class="image-frame unsafe-frame">
                        <img src="assets\img\RedFrame4.png" alt="Unsafe Frame">
                    </div>
                    <div class="image-frame unsafe-frame">
                        <img src="assets\img\RedFrame3.png" alt="Unsafe Frame">
                    </div>
                    <div class="image-frame unsafe-frame">
                        <img src="assets\img\RedFrame1.png" alt="Unsafe Frame">
                    </div>
                    <div class="image-frame unsafe-frame">
                        <img src="assets\img\RedFrame2.png" alt="Unsafe Frame">
                    </div>
                </div>
                
                <div class="text-center mt-lg">
                    <a href="https://www.kaggle.com/siddhi17/road-crossing-dataset" class="btn" target="_blank">Download Dataset</a>
                </div>
            </div>
        </div>
    </section>

    <section id="model">
        <div class="narrow-container">
            <h2>Model Architecture</h2>
            <p>After experimenting with several architectures, we developed our novel MobileNetV3-LSTM Hybrid Model that achieves state-of-the-art performance while remaining optimized for deployment on resource-constrained devices.</p>
            
            <div class="model-card">
                <h3>MobileNetV3-LSTM Hybrid Model</h3>
                
                <div class="figure">
                    <img src="assets\img\MobileNetHybrid.png" alt="MobileNetV3-LSTM Architecture" class="model-image">
                    <p class="figure-caption">Fig. 1: Architecture of MobileNetV3-LSTM Hybrid Model</p>
                </div>
                
                <p>Our best-performing model uses MobileNetV3 as a feature extractor, which is memory-efficient and lightweight, making it ideal for deployment on embedded systems like the Nvidia Jetson Nano.</p>
                
                <h4>Key Features</h4>
                <ul>
                    <li>Utilizes h-swish (hard-swish) activation function for computational efficiency and stability</li>
                    <li>Simpler mathematical operations compared to sigmoid, ideal for resource-constrained environments</li>
                    <li>Non-zero gradient characteristics contribute to stable training</li>
                    <li>Reduced computational cost for better performance on mobile devices</li>
                    <li>Uses ImageNet pre-trained weights as a starting point</li>
                    <li>Two LSTM layers with increased batch size (16) and sequence length (20)</li>
                    <li>Added L2 regularization with lambda value of 0.01</li>
                </ul>
            </div>
            
            <h3>Performance Results</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-score</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>TimeDistributed CNN-LSTM</td>
                        <td>0.6103</td>
                        <td>0.6484</td>
                        <td>0.6287</td>
                    </tr>
                    <tr>
                        <td>ResNet50-LSTM</td>
                        <td>0.708</td>
                        <td>0.693</td>
                        <td>0.7002</td>
                    </tr>
                    <tr>
                        <td>DilatedCrossNet</td>
                        <td>0.9</td>
                        <td>0.77</td>
                        <td>0.83</td>
                    </tr>
                    <tr class="highlight-row">
                        <td><strong>MobileNetV3-LSTM (Ours)</strong></td>
                        <td><strong>0.865</strong></td>
                        <td><strong>0.881</strong></td>
                        <td><strong>0.8729</strong></td>
                    </tr>
                </tbody>
            </table>
            
            <div class="figure">
                <img src="assets\img\Comparison.png" alt="Comparison of Model Metrics" class="model-image">
                <p class="figure-caption">Fig. 2: Comparison of Different Models with Metrics</p>
            </div>
            
            <p>Our results demonstrate that the MobileNetV3-LSTM model achieves the best F1-score (0.8729) and recall (0.881) among all tested models. Higher recall means our model identifies almost all safe frames, which is crucial for ensuring pedestrian safety.</p>
        </div>
    </section>

    <section id="deployment" class="alt">
        <div class="narrow-container">
            <h2>Deployment</h2>
            <p>In our final working prototype, we deployed our model on Nvidia Jetson Nano B01. We converted our pretrained TensorFlow model into a TensorRT model to optimize processing power and achieve low latency with high throughput.</p>
            
            <div class="card">
                <h3>Hardware Setup</h3>
                <div class="figure">
                    <img src="assets\img\HardwareSetUp.jpg" alt="Hardware Setup" class="model-image">
                    <p class="figure-caption">Fig. 3: Road Crossing Assistant Hardware Setup</p>
                </div>
                
                <div class="hardware-grid">
                    <div class="hardware-item">
                        <img src="assets\img\hardware-nvidia-jetson.jpg" alt="Nvidia Jetson Nano">
                        <h4>Jetson Nano B01</h4>
                        <p>Computing unit</p>
                    </div>
                    <div class="hardware-item">
                        <img src="assets\img\hardware-sjcam.jpg" alt="SJCam">
                        <h4>SJCam</h4>
                        <p>Video capture</p>
                    </div>
                    <div class="hardware-item">
                        <img src="assets\img\hardware-power-bank.jpeg" alt="Power Bank">
                        <h4>Power Bank</h4>
                        <p>Portable power</p>
                    </div>
                    <div class="hardware-item">
                        <img src="assets\img\hardware-audio-adapter.jpg" alt="Audio Adapter">
                        <h4>USB Audio</h4>
                        <p>Audio feedback</p>
                    </div>
                </div>
                
                <div class="divider"></div>
                
                <h3>Performance Improvements</h3>
                <div class="feature-grid" style="grid-template-columns: repeat(2, 1fr);">
                    <div class="feature-card">
                        <h4 class="text-center">TensorFlow Model</h4>
                        <p class="text-center" style="font-size: 32px; font-weight: 700; margin: 20px 0;">3 FPS</p>
                        <p class="text-center subtle">Original model performance</p>
                    </div>
                    <div class="feature-card">
                        <h4 class="text-center">TensorRT Model</h4>
                        <p class="text-center" style="font-size: 32px; font-weight: 700; margin: 20px 0; color: var(--accent-color);">8 FPS</p>
                        <p class="text-center subtle">Optimized model performance</p>
                    </div>
                </div>
                
                <p class="text-center">The TensorRT optimization provides a <strong>167% improvement</strong> in throughput, enabling more responsive feedback for users.</p>
                
                <div class="divider"></div>
                
                <h3>User Experience</h3>
                <p>The Road Crossing Assistant provides a seamless experience for visually impaired users:</p>
                <ul>
                    <li>Wearable, lightweight design that doesn't impede movement</li>
                    <li>Simple audio commands: "Safe to cross" and "Not safe to cross"</li>
                    <li>Continuous monitoring with real-time updates</li>
                    <li>Battery-powered operation for all-day use</li>
                    <li>Durable construction for everyday wear</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="about">
        <div class="narrow-container">
            <h2>About</h2>
            <p>We are a team of researchers and engineers focused on developing assistive technologies for the visually impaired in India. Our work addresses critical safety challenges faced by blind individuals in medium-sized Indian towns.</p>
            
            <div class="card">
                <h3>Project Impact</h3>
                <ul>
                    <li>Provides real-time auditory feedback about road crossing safety</li>
                    <li>Works with a wearable device based on affordable Nvidia Jetson Nano hardware</li>
                    <li>Specifically designed for Indian traffic conditions where formal traffic controls are often absent</li>
                    <li>Addresses a critical safety need for visually impaired individuals</li>
                    <li>Potential to save lives by preventing dangerous road crossing attempts</li>
                </ul>
            </div>
            
            <div class="team-member">
                <img src="assets\img\Kirtan.png" alt="Kirtan Prajapati">
                <h3>Kirtan Prajapati</h3>
                <p class="subtle">Master in Applied Computing</p>
            </div>
            
            <div class="text-center mt-lg">
                <a href="#" class="btn-outline">Contact Us</a>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>Â© 2025 INDRA Project</p>
            <p class="very-subtle">Presented at ICVGIP 2022</p>
        </div>
    </footer>
</body>
</html>